{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9NDmJBcxicqYzYOKY2RWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvhmadridista/BrainTumorDiagnosisUsingMRI/blob/feature%2Fmodel-training/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJECT_DIR = '/content/drive/MyDrive/ML'\n",
        "MODELS_DIR = os.path.join(PROJECT_DIR, 'models')\n",
        "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "print(\"Đã gắn Drive và thiết lập thư mục lưu trữ.\")"
      ],
      "metadata": {
        "id": "mkJnTdKK4T5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e072e8-de25-448d-b197-791e09840eed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Đã gắn Drive và thiết lập thư mục lưu trữ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b feature/model-training https://github.com/nvhmadridista/BrainTumorDiagnosisUsingMRI.git ML\n",
        "%cd ML\n",
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZGElCPS_AnZ",
        "outputId": "71f7938a-457a-4abb-edf7-656d0b48dd28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML'...\n",
            "remote: Enumerating objects: 12391, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 12391 (delta 11), reused 37 (delta 8), pack-reused 12349 (from 1)\u001b[K\n",
            "Receiving objects: 100% (12391/12391), 206.84 MiB | 16.32 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "/content/ML\n",
            "* \u001b[32mfeature/model-training\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_URL = f'https://github.com/nvhmadridista/BrainTumorDiagnosisUsingMRI/tree/feature/model-training'\n",
        "REPO_NAME = 'ML'\n",
        "!git clone {REPO_URL}\n",
        "%cd {REPO_NAME}\n"
      ],
      "metadata": {
        "id": "ca8VHQemBOwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b620422-07e0-4946-a7b5-67a877681721"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'model-training'...\n",
            "fatal: repository 'https://github.com/nvhmadridista/BrainTumorDiagnosisUsingMRI/tree/feature/model-training/' not found\n",
            "[Errno 2] No such file or directory: 'ML'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L4zN1T_z32Zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12985345-f774-4edb-c546-0a2b051c2a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ML\n",
            "Đã giải nén dữ liệu gốc vào thư mục: /content/ML/dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ML\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/KaggleData/archive.zip'\n",
        "DATASET_DIR = 'dataset'\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "!unzip -q {DRIVE_ZIP_PATH} -d {DATASET_DIR}\n",
        "print(\"Đã giải nén dữ liệu gốc vào thư mục: /content/ML/dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import math, shutil\n",
        "import os\n",
        "# Resplit images in dataset\n",
        "BASE = Path(\"dataset\")\n",
        "SRC_TRAIN = BASE / \"Training\"\n",
        "SRC_TEST = BASE / \"Testing\"\n",
        "OUT_BASE = Path(\"data_split\")\n",
        "OUT_TRAIN = OUT_BASE / \"train\"\n",
        "OUT_VAL = OUT_BASE / \"val\"\n",
        "OUT_TEST = OUT_BASE / \"test\"\n",
        "\n",
        "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "classes = sorted({p.name for p in SRC_TRAIN.iterdir() if p.is_dir()} | {p.name for p in SRC_TEST.iterdir() if p.is_dir()})\n",
        "for c in classes:\n",
        "    files = []\n",
        "    ct = SRC_TRAIN / c\n",
        "    if ct.exists():\n",
        "        files += sorted(ct.rglob(\"*.jpg\"))\n",
        "    cte = SRC_TEST / c\n",
        "    if cte.exists():\n",
        "        files += sorted(cte.rglob(\"*.jpg\"))\n",
        "    n = len(files)\n",
        "    n_train = math.floor(n * 0.70)\n",
        "    n_val = math.floor(n * 0.15)\n",
        "    n_test = n - n_train - n_val\n",
        "    splits = [(OUT_TRAIN / c, files[:n_train]), (OUT_VAL / c, files[n_train:n_train+n_val]), (OUT_TEST / c, files[n_train+n_val:])]\n",
        "    for out_dir, group in splits:\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for f in group:\n",
        "            dst = out_dir / f.name\n",
        "            if f.resolve() == dst.resolve():\n",
        "                continue\n",
        "            shutil.move(str(f), str(dst))"
      ],
      "metadata": {
        "id": "6A8iBiuH4T7b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src/preprocessing')))\n",
        "from run_preprocessing import run_main_preprocess\n",
        "if __name__ == \"__main__\":\n",
        "    tasks = [\n",
        "        (\"data_split/train\", \"data/processed/Training\"),\n",
        "        (\"data_split/val\", \"data/processed/Validation\"),\n",
        "        (\"data_split/test\", \"data/processed/Testing\"),\n",
        "    ]\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "\n",
        "for raw_dir, out_dir in tasks:\n",
        "    print(f\"\\n RUNNING PREPROCESSING: {raw_dir} - {out_dir} \")\n",
        "    run_main_preprocess(raw_dir, out_dir)\n",
        "\n",
        "print(\"\\n All Preprocessing complete. Data ready for Training.\")"
      ],
      "metadata": {
        "id": "TDXSntDG4T--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d527d452-efdf-4e2d-ba47-efa393527a15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " RUNNING PREPROCESSING: data_split/train - data/processed/Training \n",
            "Preprocessing class: pituitary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1229/1229 [00:12<00:00, 99.43it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: meningioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1151/1151 [00:11<00:00, 99.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: glioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1134/1134 [00:11<00:00, 100.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: notumor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1400/1400 [00:13<00:00, 107.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DONE! Preprocessed images from data_split/train saved in data/processed/Training\n",
            "\n",
            " RUNNING PREPROCESSING: data_split/val - data/processed/Validation \n",
            "Preprocessing class: pituitary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 263/263 [00:02<00:00, 111.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: meningioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 246/246 [00:02<00:00, 114.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: glioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:03<00:00, 78.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: notumor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:02<00:00, 107.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DONE! Preprocessed images from data_split/val saved in data/processed/Validation\n",
            "\n",
            " RUNNING PREPROCESSING: data_split/test - data/processed/Testing \n",
            "Preprocessing class: pituitary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 265/265 [00:02<00:00, 112.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: meningioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 248/248 [00:02<00:00, 115.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: glioma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 244/244 [00:02<00:00, 112.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing class: notumor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 93.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DONE! Preprocessed images from data_split/test saved in data/processed/Testing\n",
            "\n",
            " All Preprocessing complete. Data ready for Training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.training.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF6n1p8o9NW2",
        "outputId": "ca9dcf8e-23a5-4b07-d07e-30fff2e2dd7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Đã lưu tên lớp: /content/drive/MyDrive/ML/models/class_names.json\n",
            "\n",
            "Epoch 1/25\n",
            "Train Loss: 6.7123 | Train Acc: 0.3451\n",
            "Val Loss:   1.5825 | Val Acc:   0.3930\n",
            "Saved best model! Val Loss: 1.5825\n",
            "\n",
            "Epoch 2/25\n",
            "Train Loss: 1.9898 | Train Acc: 0.4397\n",
            "Val Loss:   1.2535 | Val Acc:   0.5203\n",
            "Saved best model! Val Loss: 1.2535\n",
            "\n",
            "Epoch 3/25\n",
            "Train Loss: 1.3962 | Train Acc: 0.5728\n",
            "Val Loss:   1.1433 | Val Acc:   0.6721\n",
            "Saved best model! Val Loss: 1.1433\n",
            "\n",
            "Epoch 4/25\n",
            "Train Loss: 1.0053 | Train Acc: 0.7009\n",
            "Val Loss:   0.6553 | Val Acc:   0.8062\n",
            "Saved best model! Val Loss: 0.6553\n",
            "\n",
            "Epoch 5/25\n",
            "Train Loss: 0.7549 | Train Acc: 0.7720\n",
            "Val Loss:   0.8116 | Val Acc:   0.7425\n",
            "\n",
            "Epoch 6/25\n",
            "Train Loss: 0.5886 | Train Acc: 0.8182\n",
            "Val Loss:   0.5548 | Val Acc:   0.8144\n",
            "Saved best model! Val Loss: 0.5548\n",
            "\n",
            "Epoch 7/25\n",
            "Train Loss: 0.4304 | Train Acc: 0.8669\n",
            "Val Loss:   0.4757 | Val Acc:   0.8604\n",
            "Saved best model! Val Loss: 0.4757\n",
            "\n",
            "Epoch 8/25\n",
            "Train Loss: 0.3755 | Train Acc: 0.8846\n",
            "Val Loss:   0.3623 | Val Acc:   0.8916\n",
            "Saved best model! Val Loss: 0.3623\n",
            "\n",
            "Epoch 9/25\n",
            "Train Loss: 0.3404 | Train Acc: 0.9011\n",
            "Val Loss:   0.2143 | Val Acc:   0.9363\n",
            "Saved best model! Val Loss: 0.2143\n",
            "\n",
            "Epoch 10/25\n",
            "Train Loss: 0.3062 | Train Acc: 0.9131\n",
            "Val Loss:   0.2712 | Val Acc:   0.9336\n",
            "\n",
            "Epoch 11/25\n",
            "Train Loss: 0.2354 | Train Acc: 0.9262\n",
            "Val Loss:   0.2858 | Val Acc:   0.9295\n",
            "\n",
            "Epoch 12/25\n",
            "Train Loss: 0.1681 | Train Acc: 0.9507\n",
            "Val Loss:   0.1831 | Val Acc:   0.9499\n",
            "Saved best model! Val Loss: 0.1831\n",
            "\n",
            "Epoch 13/25\n",
            "Train Loss: 0.1408 | Train Acc: 0.9583\n",
            "Val Loss:   0.2998 | Val Acc:   0.9499\n",
            "\n",
            "Epoch 14/25\n",
            "Train Loss: 0.0895 | Train Acc: 0.9727\n",
            "Val Loss:   0.3114 | Val Acc:   0.9553\n",
            "\n",
            "Epoch 15/25\n",
            "Train Loss: 0.0734 | Train Acc: 0.9739\n",
            "Val Loss:   0.1900 | Val Acc:   0.9607\n",
            "\n",
            "Epoch 16/25\n",
            "Train Loss: 0.0692 | Train Acc: 0.9784\n",
            "Val Loss:   0.2302 | Val Acc:   0.9472\n",
            "\n",
            "Epoch 17/25\n",
            "Train Loss: 0.0419 | Train Acc: 0.9847\n",
            "Val Loss:   0.1961 | Val Acc:   0.9539\n",
            "Dừng sớm: Val Loss không cải thiện sau 5 epoch.\n",
            "Đã lưu lịch sử huấn luyện tại: /content/drive/MyDrive/ML/logs/training_history.csv\n",
            "\n",
            "Training completed!\n",
            "Best Validation Accuracy: 0.9499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ML\n",
        "ZIP_FILENAME = \"brain_data_raw_and_split.zip\"\n",
        "!zip -r -q {ZIP_FILENAME}  data_split/ data/processed/\n",
        "print(f\"Đã tạo file nén chứa tất cả dữ liệu: {ZIP_FILENAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEkov8YZ9NaV",
        "outputId": "a8f5108e-8186-4083-d966-f66cb97de080"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ML\n",
            "Đã tạo file nén chứa tất cả dữ liệu: brain_data_raw_and_split.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_DATA_BACKUP = '/content/drive/MyDrive/ML/Data_Backup'\n",
        "!mkdir -p {DRIVE_DATA_BACKUP}\n",
        "!cp {ZIP_FILENAME} {DRIVE_DATA_BACKUP}/\n",
        "print(f\"Đã sao chép file nén lên Drive thành công tại: {DRIVE_DATA_BACKUP}/{ZIP_FILENAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqfuV_mh9WS_",
        "outputId": "d9cebe8e-e701-498b-a1df-4401c3996419"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã sao chép file nén lên Drive thành công tại: /content/drive/MyDrive/ML/Data_Backup/brain_data_raw_and_split.zip\n"
          ]
        }
      ]
    }
  ]
}