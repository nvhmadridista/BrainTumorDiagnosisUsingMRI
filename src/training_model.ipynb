{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqQtXxRQ9m3q",
        "outputId": "6ae7129d-0844-402f-ca0d-0f855f66a8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "env: PYTHONPATH=/content/drive/MyDrive/BrainTumorDiagnosisUsingMRI:$PYTHONPATH\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%env PYTHONPATH=/content/drive/MyDrive/BrainTumorDiagnosisUsingMRI:$PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDuewMOGiwi",
        "outputId": "55a0c097-5bd5-442f-bfc7-565210cf0f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMjZh3weOnZH",
        "outputId": "30362ac7-d4a0-4375-ff3f-d746cf5ade39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, roc_curve\n",
        ")\n",
        "\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "from dataloader.loader import get_data_loaders\n",
        "from models.hybrid_model import BrainTumorModel as HybridModel\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "print('Using device:', device)\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-4\n",
        "scheduler_choice = 'plateau'\n",
        "patience = 5\n",
        "\n",
        "data_dir = '../dataset'\n",
        "checkpoint_path = str(Path('./checkpoints/best_model_gpu.pth').resolve())\n",
        "logs_dir = Path('./logs')\n",
        "logs_dir.mkdir(parents=True, exist_ok=True)\n",
        "Path('./checkpoints').mkdir(parents=True, exist_ok=True)\n",
        "log_json_path = str((logs_dir / 'training_log_gpu.json').resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4hOOG-tklgw",
        "outputId": "bf83cde7-a21e-45fc-f266-7ee359f976f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
            "Train/Val/Test batches: 1229 66 67\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader, class_names = get_data_loaders(data_dir, batch_size=batch_size)\n",
        "num_classes = len(class_names)\n",
        "print('Classes:', class_names)\n",
        "print('Train/Val/Test batches:', len(train_loader), len(val_loader), len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iIgiliYlMpU",
        "outputId": "2857f61e-6225-41b2-c699-c8bbfb14c12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 31,635,332\n"
          ]
        }
      ],
      "source": [
        "model = HybridModel(num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'Total parameters: {total_params:,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZQIACEllRBq"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "def _batch_accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    return correct / targets.size(0)\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Train', leave=False)\n",
        "    for inputs, labels in pbar:\n",
        "        if device.type == 'cuda':\n",
        "            inputs = inputs.pin_memory().to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "        else:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(device_type=device.type):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        if device.type == 'cuda':\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_acc = _batch_accuracy(outputs.detach(), labels)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += batch_acc * inputs.size(0)\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects / total_samples\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc='Val', leave=False)\n",
        "        for inputs, labels in pbar:\n",
        "            if device.type == 'cuda':\n",
        "                inputs = inputs.pin_memory().to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "            else:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            batch_acc = _batch_accuracy(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += batch_acc * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects / total_samples\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q6GcKCrlRAQ",
        "outputId": "f6c4b993-331f-418c-e22d-ba220a0a0c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6414 | Train Acc: 0.7465\n",
            "Val   Loss: 0.5084 | Val   Acc: 0.7899\n",
            "Best model updated and saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/checkpoints/best_model_gpu.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2342 | Train Acc: 0.9179\n",
            "Val   Loss: 0.4346 | Val   Acc: 0.8470\n",
            "Best model updated and saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/checkpoints/best_model_gpu.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1442 | Train Acc: 0.9494\n",
            "Val   Loss: 0.2442 | Val   Acc: 0.9068\n",
            "Best model updated and saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/checkpoints/best_model_gpu.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0979 | Train Acc: 0.9660\n",
            "Val   Loss: 0.3656 | Val   Acc: 0.8688\n",
            "No improvement for 1 epoch(s).\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0682 | Train Acc: 0.9761\n",
            "Val   Loss: 0.3553 | Val   Acc: 0.9021\n",
            "No improvement for 2 epoch(s).\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0625 | Train Acc: 0.9777\n",
            "Val   Loss: 0.4721 | Val   Acc: 0.8783\n",
            "No improvement for 3 epoch(s).\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0197 | Train Acc: 0.9933\n",
            "Val   Loss: 0.3714 | Val   Acc: 0.9259\n",
            "Best model updated and saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/checkpoints/best_model_gpu.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0110 | Train Acc: 0.9963\n",
            "Val   Loss: 0.5016 | Val   Acc: 0.8916\n",
            "No improvement for 1 epoch(s).\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0136 | Train Acc: 0.9952\n",
            "Val   Loss: 0.2336 | Val   Acc: 0.9477\n",
            "Best model updated and saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/checkpoints/best_model_gpu.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0151 | Train Acc: 0.9952\n",
            "Val   Loss: 0.4745 | Val   Acc: 0.9087\n",
            "No improvement for 1 epoch(s).\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0136 | Train Acc: 0.9957\n",
            "Val   Loss: 0.2510 | Val   Acc: 0.9392\n",
            "No improvement for 2 epoch(s).\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0081 | Train Acc: 0.9977\n",
            "Val   Loss: 0.2985 | Val   Acc: 0.9335\n",
            "No improvement for 3 epoch(s).\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0043 | Train Acc: 0.9986\n",
            "Val   Loss: 0.3625 | Val   Acc: 0.9306\n",
            "No improvement for 4 epoch(s).\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                             "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0029 | Train Acc: 0.9987\n",
            "Val   Loss: 0.4081 | Val   Acc: 0.9344\n",
            "No improvement for 5 epoch(s).\n",
            "Early stopping triggered.\n",
            "Training log saved to: /content/drive/MyDrive/BrainTumorDiagnosisUsingMRI/src/logs/training_log_gpu.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "if scheduler_choice == 'cosine':\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "elif scheduler_choice == 'plateau':\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "else:\n",
        "    raise ValueError(\"scheduler_choice must be 'cosine' or 'plateau'\")\n",
        "\n",
        "best_val_acc = -np.inf\n",
        "epochs_no_improve = 0\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [],\n",
        "    'val_loss': [], 'val_acc': []\n",
        "}\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "\n",
        "    if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        scheduler.step(val_loss)\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "    print(f'Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f'Best model updated and saved to: {checkpoint_path}')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f'No improvement for {epochs_no_improve} epoch(s).')\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print('Early stopping triggered.')\n",
        "        break\n",
        "\n",
        "with open(log_json_path, 'w') as f:\n",
        "    json.dump({\n",
        "        'history': history,\n",
        "        'config': {\n",
        "            'batch_size': batch_size,\n",
        "            'num_epochs': num_epochs,\n",
        "            'learning_rate': learning_rate,\n",
        "            'weight_decay': weight_decay,\n",
        "            'scheduler_choice': scheduler_choice,\n",
        "            'patience': patience\n",
        "        }\n",
        "    }, f, indent=2)\n",
        "print(f'Training log saved to: {log_json_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QEH2H_tw2QCq"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc='Test', leave=False)\n",
        "        for inputs, labels in pbar:\n",
        "            if device.type == 'cuda':\n",
        "                inputs = inputs.pin_memory().to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "            else:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(inputs)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_targets.append(labels.cpu().numpy())\n",
        "\n",
        "    probs_np = np.concatenate(all_probs, axis=0)\n",
        "    preds_np = np.concatenate(all_preds, axis=0)\n",
        "    targets_np = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "    acc = accuracy_score(targets_np, preds_np)\n",
        "    f1_macro = f1_score(targets_np, preds_np, average='macro')\n",
        "\n",
        "    try:\n",
        "        from sklearn.preprocessing import label_binarize\n",
        "        targets_oh = label_binarize(targets_np, classes=np.arange(len(class_names)))\n",
        "        auc_macro = roc_auc_score(targets_oh, probs_np, average='macro', multi_class='ovr')\n",
        "    except Exception as e:\n",
        "        print('AUC computation fallback due to:', e)\n",
        "        auc_macro = float('nan')\n",
        "\n",
        "    precision, recall, f1_per_class, _ = precision_recall_fscore_support(\n",
        "        targets_np, preds_np, labels=np.arange(len(class_names)), average=None\n",
        ")\n",
        "\n",
        "    cm = confusion_matrix(targets_np, preds_np, labels=np.arange(len(class_names)))\n",
        "\n",
        "    # Confusion Matrix plot\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    im = plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     ha='center', va='center',\n",
        "                     color='white' if cm[i, j] > thresh else 'black')\n",
        "    plt.tight_layout()\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.savefig(str(logs_dir / 'confusion_matrix.png'), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # ROC curves per class\n",
        "    try:\n",
        "        from sklearn.preprocessing import label_binarize\n",
        "        targets_oh = label_binarize(targets_np, classes=np.arange(len(class_names)))\n",
        "        plt.figure(figsize=(7, 6))\n",
        "        for i in range(len(class_names)):\n",
        "            fpr, tpr, _ = roc_curve(targets_oh[:, i], probs_np[:, i])\n",
        "            auc_i = roc_auc_score(targets_oh[:, i], probs_np[:, i])\n",
        "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC={auc_i:.3f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curves (One-vs-Rest)')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(str(logs_dir / 'roc_curves.png'), bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print('ROC curve generation skipped due to:', e)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': float(acc),\n",
        "        'f1_macro': float(f1_macro),\n",
        "        'auc_macro': float(auc_macro) if not isinstance(auc_macro, float) or not np.isnan(auc_macro) else auc_macro,\n",
        "        'precision_per_class': {cls: float(precision[i]) for i, cls in enumerate(class_names)},\n",
        "        'recall_per_class': {cls: float(recall[i]) for i, cls in enumerate(class_names)},\n",
        "        'f1_per_class': {cls: float(f1_per_class[i]) for i, cls in enumerate(class_names)},\n",
        "        'confusion_matrix': cm.tolist()\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29JEYDkc3Kym",
        "outputId": "6b7b0fcc-3d37-4f32-b8b1-2549bac7ca13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded best model from checkpoint for evaluation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Metrics: {\n",
            "  \"accuracy\": 0.9735099337748344,\n",
            "  \"f1_macro\": 0.9719525182732398,\n",
            "  \"auc_macro\": 0.9956582873198215,\n",
            "  \"precision_per_class\": {\n",
            "    \"glioma\": 0.9782608695652174,\n",
            "    \"meningioma\": 0.9377431906614786,\n",
            "    \"notumor\": 0.9933333333333333,\n",
            "    \"pituitary\": 0.9814814814814815\n",
            "  },\n",
            "  \"recall_per_class\": {\n",
            "    \"glioma\": 0.9221311475409836,\n",
            "    \"meningioma\": 0.9717741935483871,\n",
            "    \"notumor\": 0.9933333333333333,\n",
            "    \"pituitary\": 1.0\n",
            "  },\n",
            "  \"f1_per_class\": {\n",
            "    \"glioma\": 0.9493670886075949,\n",
            "    \"meningioma\": 0.9544554455445544,\n",
            "    \"notumor\": 0.9933333333333333,\n",
            "    \"pituitary\": 0.9906542056074766\n",
            "  },\n",
            "  \"confusion_matrix\": [\n",
            "    [\n",
            "      225,\n",
            "      16,\n",
            "      0,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      3,\n",
            "      241,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      0,\n",
            "      298,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      0,\n",
            "      0,\n",
            "      0,\n",
            "      265\n",
            "    ]\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load best model weights before evaluation\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print('Loaded best model from checkpoint for evaluation.')\n",
        "else:\n",
        "    print('Best checkpoint not found; evaluating current model.')\n",
        "\n",
        "test_metrics = evaluate(model, test_loader)\n",
        "print('Test Metrics:', json.dumps(test_metrics, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cRLv_7p3Kxc",
        "outputId": "fc56bcb8-d66c-4250-aa86-a0787c952688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved plots to: logs\n"
          ]
        }
      ],
      "source": [
        "# Visualization: Loss and Accuracy Curves\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(str(logs_dir / 'loss_curve.png'), bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history['train_acc'], label='Train Acc')\n",
        "plt.plot(history['val_acc'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(str(logs_dir / 'accuracy_curve.png'), bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print('Saved plots to:', logs_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
