{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from models.hybrid_model import BrainTumorModel\n",
        "from dataloader.loader import get_data_loaders\n",
        "from utils.helpers import init_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"../dataset\"\n",
        "batch_size = 32\n",
        "img_size = 224\n",
        "num_epochs = 25\n",
        "lr = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODELS_DIR = './models'\n",
        "LOGS_DIR = './logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader, class_names = get_data_loaders(data_dir, batch_size, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BrainTumorModel(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "    (1): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (stage1): Sequential(\n",
              "    (0): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "      (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (1): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "      (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (2): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "      (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "  )\n",
              "  (downsample1): Sequential(\n",
              "    (0): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "  )\n",
              "  (stage2): Sequential(\n",
              "    (0): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "      (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (1): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "      (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (2): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "      (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "  )\n",
              "  (downsample2): Sequential(\n",
              "    (0): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "  )\n",
              "  (stage3): Sequential(\n",
              "    (0): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "      (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (1): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "      (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (2): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "      (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "  )\n",
              "  (downsample3): Sequential(\n",
              "    (0): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "  )\n",
              "  (stage4): Sequential(\n",
              "    (0): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "      (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (1): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "      (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "    (2): ConvNeXtBlock(\n",
              "      (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "      (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (act): GELU(approximate='none')\n",
              "      (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (drop_path): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = BrainTumorModel(num_classes=len(class_names)).to(device)\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = []\n",
        "best_val_loss = float('inf')\n",
        "best_val_acc = 0\n",
        "patience = 5\n",
        "patience_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã lưu tên lớp: ./models/class_names.json\n"
          ]
        }
      ],
      "source": [
        "class_names_path = os.path.join(MODELS_DIR, \"class_names.json\")\n",
        "with open(class_names_path, 'w') as f:\n",
        "    json.dump(class_names, f)\n",
        "print(f\"Đã lưu tên lớp: {class_names_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF6n1p8o9NW2",
        "outputId": "ca9dcf8e-23a5-4b07-d07e-30fff2e2dd7c"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    history.append({\n",
        "        'epoch': epoch + 1,\n",
        "        'train_loss': train_loss,\n",
        "        'train_acc': train_acc,\n",
        "        'val_loss': val_loss,\n",
        "        'val_acc': val_acc\n",
        "    })\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        save_path = os.path.join(MODELS_DIR, \"best_model.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Saved best model! Val Loss: {val_loss:.4f}\")\n",
        "        \n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Dừng sớm: Val Loss không cải thiện sau {patience} epoch.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_history = pd.DataFrame(history)\n",
        "log_path = os.path.join(LOGS_DIR, \"training_history.csv\")\n",
        "df_history.to_csv(log_path, index=False)\n",
        "print(f\"Đã lưu lịch sử huấn luyện tại: {log_path}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO9NDmJBcxicqYzYOKY2RWZ",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
